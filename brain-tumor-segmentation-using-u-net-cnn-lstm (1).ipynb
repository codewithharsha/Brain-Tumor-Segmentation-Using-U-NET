{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":2039896,"sourceType":"datasetVersion","datasetId":1221832},{"sourceId":2089321,"sourceType":"datasetVersion","datasetId":1252728}],"dockerImageVersionId":30068,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps  \n\n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n!pip install git+https://github.com/miykael/gif_your_nifti # nifti to gif \nimport gif_your_nifti.core as gif2nif\n\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:18.403460Z","iopub.execute_input":"2024-02-14T03:42:18.403872Z","iopub.status.idle":"2024-02-14T03:42:41.100033Z","shell.execute_reply.started":"2024-02-14T03:42:18.403765Z","shell.execute_reply":"2024-02-14T03:42:41.099261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\nfrom skimage import measure\nfrom skimage.draw import ellipsoid\nimport nibabel as nib\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:42:41.102145Z","iopub.execute_input":"2024-02-14T03:42:41.102429Z","iopub.status.idle":"2024-02-14T03:42:42.949775Z","shell.execute_reply.started":"2024-02-14T03:42:41.102402Z","shell.execute_reply":"2024-02-14T03:42:42.948957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEGMENT_CLASSES = {\n    0 : 'NOT tumor',\n    1 : 'NECROTIC/CORE',\n    2 : 'EDEMA',\n    3 : 'ENHANCING'\n}\nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 ","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:42:42.950889Z","iopub.execute_input":"2024-02-14T03:42:42.951163Z","iopub.status.idle":"2024-02-14T03:42:42.960646Z","shell.execute_reply.started":"2024-02-14T03:42:42.951137Z","shell.execute_reply":"2024-02-14T03:42:42.959883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image data descriptions\n\nAll BraTS multimodal scans are available as  NIfTI files (.nii.gz) -> commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings \n1. **T1**: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n2. **T1c**: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n3. **T2**: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n4. **FLAIR**: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n\nData were acquired with different clinical protocols and various scanners from multiple (n=19) institutions.\n\nAll the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper and in the latest BraTS summarizing paper. The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.\n\n","metadata":{}},{"cell_type":"code","source":"TRAIN_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\nVALIDATION_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n\ntest_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n\n\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:42.961864Z","iopub.execute_input":"2024-02-14T03:42:42.962147Z","iopub.status.idle":"2024-02-14T03:42:44.325562Z","shell.execute_reply.started":"2024-02-14T03:42:42.962120Z","shell.execute_reply":"2024-02-14T03:42:44.324722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show whole nifti data -> print each slice from 3d data**","metadata":{}},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:44.328635Z","iopub.execute_input":"2024-02-14T03:42:44.328948Z","iopub.status.idle":"2024-02-14T03:42:45.250305Z","shell.execute_reply.started":"2024-02-14T03:42:44.328916Z","shell.execute_reply":"2024-02-14T03:42:45.249384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show segment of tumor for each above slice**","metadata":{}},{"cell_type":"code","source":"# Skip 50:-50 slices since there is not much to see\nfig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:45.251875Z","iopub.execute_input":"2024-02-14T03:42:45.252155Z","iopub.status.idle":"2024-02-14T03:42:46.014425Z","shell.execute_reply.started":"2024-02-14T03:42:45.252126Z","shell.execute_reply":"2024-02-14T03:42:46.013514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.copy2(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii', './test_gif_BraTS20_Training_001_flair.nii')\ngif2nif.write_gif_normal('./test_gif_BraTS20_Training_001_flair.nii')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:46.016047Z","iopub.execute_input":"2024-02-14T03:42:46.016398Z","iopub.status.idle":"2024-02-14T03:42:50.128707Z","shell.execute_reply.started":"2024-02-14T03:42:46.016361Z","shell.execute_reply":"2024-02-14T03:42:50.128039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gif representation of slices in 3D volume**\n<img src=\"https://media1.tenor.com/images/15427ffc1399afc3334f12fd27549a95/tenor.gif?itemid=20554734\">","metadata":{}},{"cell_type":"markdown","source":"**Show segments of tumor using different effects**","metadata":{}},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\n\nnlplt.plot_anat(niimg,\n                title='BraTS20_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS20_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS20_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS20_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:50.129953Z","iopub.execute_input":"2024-02-14T03:42:50.130307Z","iopub.status.idle":"2024-02-14T03:42:57.182063Z","shell.execute_reply.started":"2024-02-14T03:42:50.130271Z","shell.execute_reply":"2024-02-14T03:42:57.181324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:42:57.183267Z","iopub.execute_input":"2024-02-14T03:42:57.183528Z","iopub.status.idle":"2024-02-14T03:42:57.202111Z","shell.execute_reply.started":"2024-02-14T03:42:57.183503Z","shell.execute_reply":"2024-02-14T03:42:57.201235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=128","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:42:57.203424Z","iopub.execute_input":"2024-02-14T03:42:57.203824Z","iopub.status.idle":"2024-02-14T03:42:57.216878Z","shell.execute_reply.started":"2024-02-14T03:42:57.203769Z","shell.execute_reply":"2024-02-14T03:42:57.216218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-14T03:42:57.218227Z","iopub.execute_input":"2024-02-14T03:42:57.218500Z","iopub.status.idle":"2024-02-14T03:42:59.776929Z","shell.execute_reply.started":"2024-02-14T03:42:57.218465Z","shell.execute_reply":"2024-02-14T03:42:59.775876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 70)","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:42:59.778106Z","iopub.execute_input":"2024-02-14T03:42:59.778405Z","iopub.status.idle":"2024-02-14T03:43:00.431114Z","shell.execute_reply.started":"2024-02-14T03:42:59.778376Z","shell.execute_reply":"2024-02-14T03:43:00.429998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data\nLoading all data into memory is not a good idea since the data are too big to fit in.\nSo we will create dataGenerators","metadata":{}},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:43:00.433147Z","iopub.execute_input":"2024-02-14T03:43:00.433552Z","iopub.status.idle":"2024-02-14T03:43:00.485219Z","shell.execute_reply.started":"2024-02-14T03:43:00.433509Z","shell.execute_reply":"2024-02-14T03:43:00.484577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Override Keras sequence DataGenerator class**","metadata":{}},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-14T03:43:00.486374Z","iopub.execute_input":"2024-02-14T03:43:00.486676Z","iopub.status.idle":"2024-02-14T03:43:00.504662Z","shell.execute_reply.started":"2024-02-14T03:43:00.486647Z","shell.execute_reply":"2024-02-14T03:43:00.503634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of data used**\nfor training / testing / validation","metadata":{}},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n\n    plt.show()\n    \nshowDataLayout()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:43:00.506063Z","iopub.execute_input":"2024-02-14T03:43:00.506360Z","iopub.status.idle":"2024-02-14T03:43:00.636290Z","shell.execute_reply.started":"2024-02-14T03:43:00.506318Z","shell.execute_reply":"2024-02-14T03:43:00.635564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Add callback for training process**","metadata":{}},{"cell_type":"code","source":"csv_logger = CSVLogger('training.log', separator=',', append=False)\n\n\ncallbacks = [\n#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n#                               patience=2, verbose=1, mode='auto'),\n      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1),\n#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n#                             verbose=1, save_best_only=True, save_weights_only = True)\n        csv_logger\n    ]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-14T03:43:00.637221Z","iopub.execute_input":"2024-02-14T03:43:00.637468Z","iopub.status.idle":"2024-02-14T03:43:00.642186Z","shell.execute_reply.started":"2024-02-14T03:43:00.637443Z","shell.execute_reply":"2024-02-14T03:43:00.641136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:43:00.643489Z","iopub.execute_input":"2024-02-14T03:43:00.643790Z","iopub.status.idle":"2024-02-14T03:43:00.667313Z","shell.execute_reply.started":"2024-02-14T03:43:00.643757Z","shell.execute_reply":"2024-02-14T03:43:00.666461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history =  model.fit(training_generator,\n                    epochs=35,\n                    steps_per_epoch=len(train_ids),\n                    callbacks= callbacks,\n                    validation_data = valid_generator\n                    )  \nmodel.save(\"my_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:45:17.640995Z","iopub.execute_input":"2024-02-14T03:45:17.641355Z","iopub.status.idle":"2024-02-14T03:55:18.938932Z","shell.execute_reply.started":"2024-02-14T03:45:17.641325Z","shell.execute_reply":"2024-02-14T03:55:18.937914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize the training process**","metadata":{}},{"cell_type":"code","source":"model = keras.models.load_model('../input/modelperclasseval/model_per_class.h5', \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n                                                   \"dice_coef_edema\": dice_coef_edema,\n                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n                                                  }, compile=False)\n\nhistory = pd.read_csv('../input/modelperclasseval/training_per_class.log', sep=',', engine='python')\n\nhist=history\n\n# hist=history.history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:30:38.584693Z","iopub.execute_input":"2024-02-08T15:30:38.585100Z","iopub.status.idle":"2024-02-08T15:30:40.126196Z","shell.execute_reply.started":"2024-02-08T15:30:38.585066Z","shell.execute_reply":"2024-02-08T15:30:40.125287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction examples ","metadata":{}},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n\n\n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n# brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-08T15:30:42.180830Z","iopub.execute_input":"2024-02-08T15:30:42.181211Z","iopub.status.idle":"2024-02-08T15:30:42.193454Z","shell.execute_reply.started":"2024-02-08T15:30:42.181174Z","shell.execute_reply":"2024-02-08T15:30:42.192466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    flair=nib.load(vol_path).get_fdata()\n    \n    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    \n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\n\ndef showPredictsById(case, start_slice = 60):\n    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n    \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0][-3:])\nshowPredictsById(case=test_ids[1][-3:])\nshowPredictsById(case=test_ids[2][-3:])\nshowPredictsById(case=test_ids[3][-3:])\nshowPredictsById(case=test_ids[4][-3:])\nshowPredictsById(case=test_ids[5][-3:])\nshowPredictsById(case=test_ids[6][-3:])\n\n\nmask = np.zeros((10,10))\nmask[3:-3, 3:-3] = 1 # white square in black background\nim = mask + np.random.randn(10,10) * 0.01 # random image\nmasked = np.ma.masked_where(mask == 0, mask)\n\nplt.figure()\nplt.subplot(1,2,1)\nplt.imshow(im, 'gray', interpolation='none')\nplt.subplot(1,2,2)\nplt.imshow(im, 'gray', interpolation='none')\nplt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:31:01.023776Z","iopub.execute_input":"2024-02-08T15:31:01.024121Z","iopub.status.idle":"2024-02-08T15:31:08.368106Z","shell.execute_reply.started":"2024-02-08T15:31:01.024091Z","shell.execute_reply":"2024-02-08T15:31:08.367100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"case = case=test_ids[3][-3:]\npath = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\ngt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\np = predictByPath(path,case)\n\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ni=40 # slice at\neval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\n\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-02-08T15:31:15.583343Z","iopub.execute_input":"2024-02-08T15:31:15.583726Z","iopub.status.idle":"2024-02-08T15:31:16.174209Z","shell.execute_reply.started":"2024-02-08T15:31:15.583677Z","shell.execute_reply":"2024-02-08T15:31:16.173513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Advanced Plotting**","metadata":{}},{"cell_type":"code","source":"from skimage import measure\n\ndef visualize_with_marching_cubes(prediction, threshold=0.5):\n    binary_masks = prediction > threshold\n    verts, faces, _, _ = measure.marching_cubes(binary_masks, 0)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:46:36.537719Z","iopub.execute_input":"2024-02-08T15:46:36.538074Z","iopub.status.idle":"2024-02-08T15:46:36.543046Z","shell.execute_reply.started":"2024-02-08T15:46:36.538046Z","shell.execute_reply":"2024-02-08T15:46:36.542027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_with_marching_cubes(core)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:49:03.314789Z","iopub.execute_input":"2024-02-08T15:49:03.315157Z","iopub.status.idle":"2024-02-08T15:49:03.353295Z","shell.execute_reply.started":"2024-02-08T15:49:03.315121Z","shell.execute_reply":"2024-02-08T15:49:03.352335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_with_marching_cubes(edema)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:58:07.140780Z","iopub.execute_input":"2024-02-08T15:58:07.141130Z","iopub.status.idle":"2024-02-08T15:58:07.235930Z","shell.execute_reply.started":"2024-02-08T15:58:07.141100Z","shell.execute_reply":"2024-02-08T15:58:07.235063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_with_marching_cubes(enhancing)","metadata":{"execution":{"iopub.status.busy":"2024-02-08T15:58:35.964618Z","iopub.execute_input":"2024-02-08T15:58:35.964974Z","iopub.status.idle":"2024-02-08T15:58:36.002828Z","shell.execute_reply.started":"2024-02-08T15:58:35.964933Z","shell.execute_reply":"2024-02-08T15:58:36.001967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RESNET 50 Model ","metadata":{}},{"cell_type":"code","source":"!pip3 install -U segmentation-models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm\nimport tensorflow as tf\ntf.keras.backend.set_image_data_format('channels_last')","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:21.657171Z","iopub.execute_input":"2024-02-14T03:58:21.657515Z","iopub.status.idle":"2024-02-14T03:58:29.789530Z","shell.execute_reply.started":"2024-02-14T03:58:21.657485Z","shell.execute_reply":"2024-02-14T03:58:29.788641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code mới\nimport sys\nimport os\nimport glob\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.model_selection import train_test_split\nfrom segmentation_models import Unet, Linknet, PSPNet, FPN\nimport keras\nfrom segmentation_models.utils import set_trainable\nfrom torch.utils.data import Dataset\nfrom keras.models import load_model\nfrom tensorflow.keras import utils as np_utils","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:29.791892Z","iopub.execute_input":"2024-02-14T03:58:29.792302Z","iopub.status.idle":"2024-02-14T03:58:31.258739Z","shell.execute_reply.started":"2024-02-14T03:58:29.792244Z","shell.execute_reply":"2024-02-14T03:58:31.257789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:31.260125Z","iopub.execute_input":"2024-02-14T03:58:31.260411Z","iopub.status.idle":"2024-02-14T03:58:31.278550Z","shell.execute_reply.started":"2024-02-14T03:58:31.260382Z","shell.execute_reply":"2024-02-14T03:58:31.277813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\ntrain_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) ","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:31.279689Z","iopub.execute_input":"2024-02-14T03:58:31.279997Z","iopub.status.idle":"2024-02-14T03:58:31.306322Z","shell.execute_reply.started":"2024-02-14T03:58:31.279966Z","shell.execute_reply":"2024-02-14T03:58:31.305504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 128\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:31.308901Z","iopub.execute_input":"2024-02-14T03:58:31.309263Z","iopub.status.idle":"2024-02-14T03:58:31.325991Z","shell.execute_reply.started":"2024-02-14T03:58:31.309226Z","shell.execute_reply":"2024-02-14T03:58:31.325182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n\n    plt.show()\n    \nshowDataLayout()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T03:58:31.327646Z","iopub.execute_input":"2024-02-14T03:58:31.328026Z","iopub.status.idle":"2024-02-14T03:58:31.457140Z","shell.execute_reply.started":"2024-02-14T03:58:31.327989Z","shell.execute_reply":"2024-02-14T03:58:31.456351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('training_ResNet.log', separator=',', append=False)\n\n\ncallbacks = [\n#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n#                               patience=2, verbose=1, mode='auto'),\n      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1),\n#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n#                             verbose=1, save_best_only=True, save_weights_only = True)\n        csv_logger\n    ]","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:33:26.431656Z","iopub.execute_input":"2024-02-14T04:33:26.432060Z","iopub.status.idle":"2024-02-14T04:33:26.437665Z","shell.execute_reply.started":"2024-02-14T04:33:26.432026Z","shell.execute_reply":"2024-02-14T04:33:26.436537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE = 'resnet50'\n\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\n# define network parameters\nn_classes = 4 # case for binary and multiclass segmentation\nactivation = 'softmax'\n\n#create model\nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation, encoder_weights=None, encoder_freeze=True, input_shape = (128,128,2))\n\n# compile keras model with defined optimozer, loss and metrics\n# model.compile(loss=\"categorical_crossentropy\",\n#               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n#               metrics = [accuracy, dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:33:30.153642Z","iopub.execute_input":"2024-02-14T04:33:30.154031Z","iopub.status.idle":"2024-02-14T04:33:31.250638Z","shell.execute_reply.started":"2024-02-14T04:33:30.153994Z","shell.execute_reply":"2024-02-14T04:33:31.249952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\n\nhistory =  model.fit(training_generator,\n                     epochs=35,\n                     steps_per_epoch=len(train_ids),\n                     callbacks= callbacks,\n                     validation_data = valid_generator\n                     )  \nmodel.save(\"RESNET_35EP_0_DOC_001.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:33:35.752524Z","iopub.execute_input":"2024-02-14T04:33:35.752898Z","iopub.status.idle":"2024-02-14T04:49:52.846666Z","shell.execute_reply.started":"2024-02-14T04:33:35.752860Z","shell.execute_reply":"2024-02-14T04:49:52.844396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.ylabel('loss')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:28:34.716090Z","iopub.execute_input":"2024-02-14T04:28:34.716495Z","iopub.status.idle":"2024-02-14T04:28:34.871825Z","shell.execute_reply.started":"2024-02-14T04:28:34.716458Z","shell.execute_reply":"2024-02-14T04:28:34.871000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:28:36.358539Z","iopub.execute_input":"2024-02-14T04:28:36.358925Z","iopub.status.idle":"2024-02-14T04:28:36.512720Z","shell.execute_reply.started":"2024-02-14T04:28:36.358888Z","shell.execute_reply":"2024-02-14T04:28:36.511938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['dice_coef'])\nplt.ylabel('dice_coef')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:28:38.342561Z","iopub.execute_input":"2024-02-14T04:28:38.343136Z","iopub.status.idle":"2024-02-14T04:28:38.501873Z","shell.execute_reply.started":"2024-02-14T04:28:38.343097Z","shell.execute_reply":"2024-02-14T04:28:38.500912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['sensitivity'])\nplt.ylabel('sensitivity')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:31:56.415055Z","iopub.execute_input":"2024-02-12T18:31:56.415446Z","iopub.status.idle":"2024-02-12T18:31:56.591098Z","shell.execute_reply.started":"2024-02-12T18:31:56.415412Z","shell.execute_reply":"2024-02-12T18:31:56.590302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['specificity'])\nplt.ylabel('specificity')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:32:04.780020Z","iopub.execute_input":"2024-02-12T18:32:04.780413Z","iopub.status.idle":"2024-02-12T18:32:04.944457Z","shell.execute_reply.started":"2024-02-12T18:32:04.780376Z","shell.execute_reply":"2024-02-12T18:32:04.943522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['dice_coef_necrotic'])\nplt.ylabel('dice_coef_necrotic')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:32:14.988552Z","iopub.execute_input":"2024-02-12T18:32:14.988906Z","iopub.status.idle":"2024-02-12T18:32:15.163302Z","shell.execute_reply.started":"2024-02-12T18:32:14.988876Z","shell.execute_reply":"2024-02-12T18:32:15.162471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['dice_coef_edema'])\nplt.ylabel('dice_coef_edema')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:32:29.148617Z","iopub.execute_input":"2024-02-12T18:32:29.148971Z","iopub.status.idle":"2024-02-12T18:32:29.320356Z","shell.execute_reply.started":"2024-02-12T18:32:29.148941Z","shell.execute_reply":"2024-02-12T18:32:29.319538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['dice_coef_enhancing'])\nplt.ylabel('dice_coef_enhancing')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:32:53.061428Z","iopub.execute_input":"2024-02-12T18:32:53.061771Z","iopub.status.idle":"2024-02-12T18:32:53.223648Z","shell.execute_reply.started":"2024-02-12T18:32:53.061743Z","shell.execute_reply":"2024-02-12T18:32:53.222822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_accuracy'])\nplt.ylabel('val_accuracy')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:33:06.799923Z","iopub.execute_input":"2024-02-12T18:33:06.800299Z","iopub.status.idle":"2024-02-12T18:33:06.958605Z","shell.execute_reply.started":"2024-02-12T18:33:06.800267Z","shell.execute_reply":"2024-02-12T18:33:06.957857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_dice_coef'])\nplt.ylabel(' val_dice_coef')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:33:34.208543Z","iopub.execute_input":"2024-02-12T18:33:34.208908Z","iopub.status.idle":"2024-02-12T18:33:34.362092Z","shell.execute_reply.started":"2024-02-12T18:33:34.208873Z","shell.execute_reply":"2024-02-12T18:33:34.361322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_precision'])\nplt.ylabel(' val_precision')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:33:44.304728Z","iopub.execute_input":"2024-02-12T18:33:44.305082Z","iopub.status.idle":"2024-02-12T18:33:44.455192Z","shell.execute_reply.started":"2024-02-12T18:33:44.305042Z","shell.execute_reply":"2024-02-12T18:33:44.454314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_sensitivity'])\nplt.ylabel(' val_sensitivity')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:33:53.867702Z","iopub.execute_input":"2024-02-12T18:33:53.868080Z","iopub.status.idle":"2024-02-12T18:33:54.032506Z","shell.execute_reply.started":"2024-02-12T18:33:53.868034Z","shell.execute_reply":"2024-02-12T18:33:54.031558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_specificity'])\nplt.ylabel(' val_specificity')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:34:00.229678Z","iopub.execute_input":"2024-02-12T18:34:00.230041Z","iopub.status.idle":"2024-02-12T18:34:00.394114Z","shell.execute_reply.started":"2024-02-12T18:34:00.230009Z","shell.execute_reply":"2024-02-12T18:34:00.393279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_dice_coef_necrotic'])\nplt.ylabel(' val_dice_coef_necrotic')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:34:06.639350Z","iopub.execute_input":"2024-02-12T18:34:06.639712Z","iopub.status.idle":"2024-02-12T18:34:06.804938Z","shell.execute_reply.started":"2024-02-12T18:34:06.639676Z","shell.execute_reply":"2024-02-12T18:34:06.804207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['val_dice_coef_enhancing'])\nplt.ylabel(' val_dice_coef_enhancing')\nplt.xlabel('Epoch')","metadata":{"execution":{"iopub.status.busy":"2024-02-12T18:34:21.073908Z","iopub.execute_input":"2024-02-12T18:34:21.074259Z","iopub.status.idle":"2024-02-12T18:34:21.224134Z","shell.execute_reply.started":"2024-02-12T18:34:21.074231Z","shell.execute_reply":"2024-02-12T18:34:21.223391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_unet = pd.read_csv('/kaggle/working/training.log', sep=',', engine='python')\nhistory_unet.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:54:37.971426Z","iopub.execute_input":"2024-02-14T04:54:37.971784Z","iopub.status.idle":"2024-02-14T04:54:38.003181Z","shell.execute_reply.started":"2024-02-14T04:54:37.971754Z","shell.execute_reply":"2024-02-14T04:54:38.002327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_resnet = pd.read_csv('/kaggle/working/training_ResNet.log', sep=',', engine='python')\nhistory_resnet.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T04:54:48.314789Z","iopub.execute_input":"2024-02-14T04:54:48.315185Z","iopub.status.idle":"2024-02-14T04:54:48.343819Z","shell.execute_reply.started":"2024-02-14T04:54:48.315152Z","shell.execute_reply":"2024-02-14T04:54:48.343114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy comparision\nunet_accuracies = history_unet['accuracy']\nresnet_accuracies = history_resnet[\"accuracy\"][:5]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet_accuracies) / len(unet_accuracies), sum(resnet_accuracies) / len(resnet_accuracies)], bar_width, label='Mean Accuracy')\nplt.bar([i + bar_width for i in index], [max(unet_accuracies), max(resnet_accuracies)], bar_width, label='Max Accuracy')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Accuracy (%)')\nplt.title('Accuracy Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:39:20.227846Z","iopub.execute_input":"2024-02-14T05:39:20.228196Z","iopub.status.idle":"2024-02-14T05:39:20.380915Z","shell.execute_reply.started":"2024-02-14T05:39:20.228165Z","shell.execute_reply":"2024-02-14T05:39:20.379746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diec_coeff comparision\nunet = history_unet['dice_coef']\nresnet = history_resnet[\"dice_coef\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Diec Coeff')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Diec Coeff')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Diec Coeff (%)')\nplt.title('Diec Coeff Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:44:08.762320Z","iopub.execute_input":"2024-02-14T05:44:08.762665Z","iopub.status.idle":"2024-02-14T05:44:08.910196Z","shell.execute_reply.started":"2024-02-14T05:44:08.762634Z","shell.execute_reply":"2024-02-14T05:44:08.909303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diec_coeff comparision\nunet = history_unet['dice_coef_edema']\nresnet = history_resnet[\"dice_coef_edema\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Diec Coeff Edema')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Diec Coeff Edema')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Diec Coeff Edema(%)')\nplt.title('Diec Coeff of Edema Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:45:07.042893Z","iopub.execute_input":"2024-02-14T05:45:07.043237Z","iopub.status.idle":"2024-02-14T05:45:07.202017Z","shell.execute_reply.started":"2024-02-14T05:45:07.043208Z","shell.execute_reply":"2024-02-14T05:45:07.201120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diec_coeff comparision\nunet = history_unet['dice_coef_enhancing']\nresnet = history_resnet[\"dice_coef_enhancing\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Diec Coeff Enhancing')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Diec Coeff Enhancing')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Diec Coeff Enhancing(%)')\nplt.title('Diec Coeff Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:46:14.035134Z","iopub.execute_input":"2024-02-14T05:46:14.035507Z","iopub.status.idle":"2024-02-14T05:46:14.196438Z","shell.execute_reply.started":"2024-02-14T05:46:14.035477Z","shell.execute_reply":"2024-02-14T05:46:14.195518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diec_coeff comparision\nunet = history_unet['dice_coef_necrotic']\nresnet = history_resnet[\"dice_coef_necrotic\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Diec Coeff Necrotic')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Diec Coeff Necrotic')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Diec Coeff Necrotic(%)')\nplt.title('Diec Coeff Necrotic Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:47:14.834278Z","iopub.execute_input":"2024-02-14T05:47:14.834611Z","iopub.status.idle":"2024-02-14T05:47:14.999145Z","shell.execute_reply.started":"2024-02-14T05:47:14.834581Z","shell.execute_reply":"2024-02-14T05:47:14.998337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loss comparision\nunet = history_unet['loss']\nresnet = history_resnet[\"val_loss\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean loss')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max loss')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('loss)')\nplt.title('loss Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:51:08.372132Z","iopub.execute_input":"2024-02-14T05:51:08.372509Z","iopub.status.idle":"2024-02-14T05:51:08.520849Z","shell.execute_reply.started":"2024-02-14T05:51:08.372473Z","shell.execute_reply":"2024-02-14T05:51:08.520082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#diec_coeff comparision\nunet = history_unet['lr']\nresnet = history_resnet[\"lr\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean lr')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max lr')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('LR)')\nplt.title('LR Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:49:03.838649Z","iopub.execute_input":"2024-02-14T05:49:03.839002Z","iopub.status.idle":"2024-02-14T05:49:03.991710Z","shell.execute_reply.started":"2024-02-14T05:49:03.838972Z","shell.execute_reply":"2024-02-14T05:49:03.990869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Precision comparision\nunet = history_unet['precision']\nresnet = history_resnet[\"precision\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Precision')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Precision')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Precision)')\nplt.title('Precision Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:58:23.077479Z","iopub.execute_input":"2024-02-14T05:58:23.077887Z","iopub.status.idle":"2024-02-14T05:58:23.231705Z","shell.execute_reply.started":"2024-02-14T05:58:23.077847Z","shell.execute_reply":"2024-02-14T05:58:23.230953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sensitivity comparision\nunet = history_unet['sensitivity']\nresnet = history_resnet[\"sensitivity\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean sensitivity')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max sensitivity')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('sensitivity)')\nplt.title('sensitivity Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:58:59.781154Z","iopub.execute_input":"2024-02-14T05:58:59.781529Z","iopub.status.idle":"2024-02-14T05:58:59.935154Z","shell.execute_reply.started":"2024-02-14T05:58:59.781495Z","shell.execute_reply":"2024-02-14T05:58:59.934359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#specificity comparision\nunet = history_unet['specificity']\nresnet = history_resnet[\"specificity\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean specificity')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max specificity')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('specificity)')\nplt.title('specificity Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T05:59:31.952483Z","iopub.execute_input":"2024-02-14T05:59:31.952859Z","iopub.status.idle":"2024-02-14T05:59:32.107583Z","shell.execute_reply.started":"2024-02-14T05:59:31.952817Z","shell.execute_reply":"2024-02-14T05:59:32.106805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#IOU comparision\nunet = history_unet['mean_io_u_1']\nresnet = history_resnet[\"mean_io_u\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean IOU')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max IOU')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('IOU)')\nplt.title('IOU Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T06:09:33.255526Z","iopub.execute_input":"2024-02-14T06:09:33.255927Z","iopub.status.idle":"2024-02-14T06:09:33.416295Z","shell.execute_reply.started":"2024-02-14T06:09:33.255894Z","shell.execute_reply":"2024-02-14T06:09:33.415384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation accuracy comparision\nunet_accuracies = history_unet['val_accuracy']\nresnet_accuracies = history_resnet[\"val_accuracy\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet_accuracies) / len(unet_accuracies), sum(resnet_accuracies) / len(resnet_accuracies)], bar_width, label='Mean Accuracy')\nplt.bar([i + bar_width for i in index], [max(unet_accuracies), max(resnet_accuracies)], bar_width, label='Max Accuracy')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('val_Accuracy (%)')\nplt.title('val_Accuracy Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T06:10:54.472807Z","iopub.execute_input":"2024-02-14T06:10:54.473169Z","iopub.status.idle":"2024-02-14T06:10:54.625994Z","shell.execute_reply.started":"2024-02-14T06:10:54.473139Z","shell.execute_reply":"2024-02-14T06:10:54.625058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#val_diec_coeff comparision\nunet = history_unet['val_dice_coef']\nresnet = history_resnet[\"val_dice_coef\"]\n\nnum_models = 2\n# Index for each bar\nindex = range(num_models)\n\n# Plotting the bar graph\nplt.bar(index, [sum(unet) / len(unet), sum(resnet) / len(resnet)], bar_width, label='Mean Validation Diec Coeff')\nplt.bar([i + bar_width for i in index], [max(unet), max(resnet)], bar_width, label='Max Validation Diec Coeff')\n\n# Adding labels and title\nplt.xlabel('Models')\nplt.ylabel('Validation Diec Coeff (%)')\nplt.title('Validation Diec Coeff Comparison between U-Net and ResNet')\nplt.xticks([i + bar_width / 2 for i in index], ['U-Net', 'ResNet'])\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-14T06:15:12.041814Z","iopub.execute_input":"2024-02-14T06:15:12.042213Z","iopub.status.idle":"2024-02-14T06:15:12.221616Z","shell.execute_reply.started":"2024-02-14T06:15:12.042179Z","shell.execute_reply":"2024-02-14T06:15:12.220845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}